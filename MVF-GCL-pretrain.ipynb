{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.sparse as sp\n",
    "from time import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,multilabel_confusion_matrix,roc_curve,roc_auc_score\n",
    "# from gin import Encoder, GAT\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import MessagePassing, global_add_pool, global_sort_pool, GCNConv, GATConv\n",
    "from torch_geometric.data import Dataset, InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('./')\n",
    "from pytorchtools import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from RGCN import res_GCN, MV_MGCL, cal_GCL, cal_GCL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3407  #3701, 3407\n",
    "# 生成随机数，以便固定后续随机数，方便复现代码\n",
    "random.seed(seed)\n",
    "# 没有使用GPU的时候设置的固定生成的随机数\n",
    "np.random.seed(seed)\n",
    "# 为CPU设置种子用于生成随机数，以使得结果是确定的\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed()为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([1,0,0,1])\n",
    "# b = torch.tensor([1,0,0,1])\n",
    "# a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z = torch.rand(10, 4)\n",
    "# B = torch.rand(10, 4)\n",
    "\n",
    "# Z_norm = torch.linalg.norm(Z, dim=1, keepdim=True)  # Size (n, 1).\n",
    "# B_norm = torch.linalg.norm(B, dim=1, keepdim=True)  # Size (1, b).\n",
    "\n",
    "# # Distance matrix of size (b, n).\n",
    "# cosine_similarity = ((Z.T @ B) / (Z_norm.T @ B_norm)).T\n",
    "# cosine_distance = 1 - cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.cosine_similarity(Z, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型扰动\n",
    "# def gen_ran_output(data, model, vice_model, eta):\n",
    "#     for (adv_name,adv_param), (name,param) in zip(vice_model.named_parameters(), model.named_parameters()):\n",
    "#         if name.split('.')[0] == 'proj_head': #映射层参数不变化。\n",
    "#             adv_param.data = param.data\n",
    "#         else:\n",
    "#             adv_param.data = param.data + eta * torch.normal(0,torch.ones_like(param.data)*param.data.std()).to(device)   #GNN模型参数扰动，Gasussio       \n",
    "#     z2 = vice_model(data.x, data.edge_index, data.edge_attr, data.batch, data.num_graphs)\n",
    "#     return z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[1.2,2.3],[3,4],[5,6]])\n",
    "# b = torch.tensor([[1.2,2.3],[3,4],[5,6]])\n",
    "# a = torch.einsum('ik,jk->ij', a, b)\n",
    "# b = torch.einsum('i,j->ij', b.norm(dim=1), a.norm(dim=1))\n",
    "# a = a/b\n",
    "# b = a[range(3),range(3)]\n",
    "# # lo = b / a.sum(dim=1)\n",
    "# # lo\n",
    "# a,b,a.sum(dim=1),a.sum()\n",
    "# [item for item in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.tensor([1,2,3,4,5,6])\n",
    "# t[range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset generator\n",
    "class SG(InMemoryDataset):\n",
    "    global d_type\n",
    "    def __init__(self, root, transform=None, pre_transform=None,pre_filter=None):\n",
    "        super().__init__(root, transform=None, pre_transform=None, pre_filter=None)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return osp.join(self.root, '/raw/'+d_type)\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return os.listdir(self.root+'/raw/'+d_type)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "#         return ['pre-train.pt']\n",
    "        return [d_type+'.pt']\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for raw_path in tqdm(self.raw_paths):\n",
    "            edges = []\n",
    "            edge_features = []\n",
    "            nodes = []\n",
    "            node_features = []\n",
    "            with open(self.root+raw_path,'r') as f:\n",
    "                row = f.readline().strip().split()\n",
    "                nodes_num,label = [int(w) for w in row]\n",
    "                for line,j in zip(f.readlines(),range(nodes_num)):\n",
    "                    row = line.strip().split()\n",
    "                    row ,attr = [int(w) for w in row[1:int(row[0])+1]],np.array([float(w) for w in row[int(row[0])+1:]])\n",
    "                    if attr is not None:\n",
    "                        node_features.append(attr)\n",
    "                    if row is not None:\n",
    "                        for k in row:\n",
    "                            edge = [j,k]\n",
    "                            edges.append(edge)\n",
    "            for edge in edges:\n",
    "                edge_features.append((node_features[edge[0]]+node_features[edge[1]])/2)\n",
    "            num_edges = len(edges)\n",
    "            new_edges = torch.zeros((2,num_edges),dtype=torch.long)\n",
    "            for edge,index in zip(edges,range(num_edges)):\n",
    "                new_edges[0,index] = edge[0]\n",
    "                new_edges[1,index] = edge[1]\n",
    "            node_features = torch.tensor(node_features,dtype=torch.float)\n",
    "            nodes = torch.tensor(nodes,dtype=torch.long)\n",
    "            edge_features = torch.tensor(edge_features,dtype=torch.float)\n",
    "            data = Data(x=node_features,edge_index=new_edges,edge_attr=edge_features)\n",
    "            data_list.append(data)\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "input_dim = 100\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "num_gc_layers = 10\n",
    "k = 100\n",
    "lr = 0.01\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# model = symmetric_sim(input_dim, hidden_dim, num_gc_layers, output_dim, k).to(device)\n",
    "model = MV_MGCL(input_dim, hidden_dim, num_gc_layers, output_dim, k).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.05 ,cycle_momentum = False)\n",
    "\n",
    "d_type = 'multi-2'\n",
    "dataset = SG('/media/bmw_lab/2eb7452f-ae82-4707-82ed-218aabcd7aaf1/bmw_lab/frankda/CL-Pre_train/dataset/pre-train')\n",
    "dataloader = DataLoader(dataset, batch_size = 64, shuffle = True)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True, path='./saved_models/pre-train-64-10-(multi2_k100_no_relu_epoch100_rgcn_wo_ln_simplified_projhead_MV_MGCL_cal_GCL2).pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    loss_history = []\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        loss_all = 0\n",
    "        model.train()\n",
    "        for data in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            node_num, _ = data.x.size()\n",
    "            data = data.to(device)\n",
    "#             nega = negative_model(data.x, data.edge_index, data.edge_attr, data.batch, data.num_graphs)\n",
    "            # to_dense_adj(edge_index, batch=None, edge_attr=None, max_num_nodes=None)\n",
    "\n",
    "            adj = to_dense_adj(data.edge_index).squeeze()\n",
    "            node_degs = torch.sum(adj, dim = 1) + 1\n",
    "            node_degs = 1/ node_degs\n",
    "            node_degs = torch.diag(node_degs).to(device)     #x, edge_index, edge_attr, batch, num_graphs, graphs, degs, eta, device\n",
    "            rgcn_output, aug_rgcn_output, gat_output, aug_gat_output = model(data.x, data.edge_index, data.edge_attr, data.batch, data.num_graphs, adj, node_degs, eta=1.0, device=device)\n",
    "            \n",
    "            # loss = cal_pos_loss(gcn_output, augument_output, nega)\n",
    "            # loss = model.cal_loss(aug_gcn_output, aug_gat_output, nega_gcn_output, nega_gat_output)\n",
    "            # loss_intra = cal_GCL(rgcn_output, aug_rgcn_output) + cal_GCL(gat_output, aug_gat_output)\n",
    "            # loss_inter = cal_GCL(rgcn_output, gat_output)\n",
    "            loss_intra = cal_GCL2(rgcn_output, aug_rgcn_output) + cal_GCL2(gat_output, aug_gat_output)\n",
    "            loss_inter = cal_GCL2(rgcn_output, gat_output)\n",
    "            # loss = cal_pos_loss2(gcn_output, augument_output, nega_output)\n",
    "            loss = loss_inter + 0.5 * loss_intra\n",
    "            loss_all += loss.cpu().item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             optimizer_nega.step()\n",
    "            scheduler.step()\n",
    "#             scheduler_nega.step()\n",
    "        loss_epoch = loss_all / len(dataloader)\n",
    "        loss_history.append(loss_epoch)\n",
    "        drawLoss(loss_history)\n",
    "        with open('./results/pre-train.txt','a') as f:\n",
    "            print('Epoch {}, Loss {}, Loss_inter {}, Loss_intra {}'.format(epoch, loss_epoch, loss_inter, loss_intra), file=f)\n",
    "        early_stopping(loss_epoch, model)\n",
    "        if early_stopping.early_stop:\n",
    "#             model.load_state_dict(torch.load('pre-train.pt'))\n",
    "            break;\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLoss(history):\n",
    "#     plt.xlim([0,10000])\n",
    "    plt.ylim([0,0.5])\n",
    "    plt.plot(history,'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on  multi-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmw_lab/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'nn.glob.global_sort_pool' is deprecated, use 'nn.aggr.SortAggr' instead\n",
      "  warnings.warn(out)\n",
      " 20%|██        | 1/5 [01:22<05:29, 82.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 8.314610).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:41<04:04, 81.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (8.314610 --> 8.312651).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [04:02<02:42, 81.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (8.312651 --> 8.312648).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [05:22<01:20, 80.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (8.312648 --> 8.312647).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:42<00:00, 80.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (8.312647 --> 8.312647).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('train on ',d_type)\n",
    "loss_history = train(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "drawLoss(loss_history)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7c5d2e92ae5a023dcd4c2e97ccc2f57353f7b97bc17310d395b60c853ef50c9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
